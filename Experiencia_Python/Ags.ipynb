{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ags.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UlYBpbWTFBK"
      },
      "outputs": [],
      "source": [
        "# Inicializacion\n",
        "t = 0 #generacion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math as mt\n",
        "import random as rd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Y6kJI34LBNcC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agsimple():\n",
        "    import math as m\n",
        "    t = 0 #generacion\n",
        "    #cal_fit = lambda l_x: mt.pow(1.5 - l_x[0]*(1-l_x[1]),2) + mt.pow( 2.25 - l_x[0]*(1-mt.pow(l_x[1],2)) ,2) + mt.pow( 2.625 - l_x[0]*(1-mt.pow(l_x[1],3)) ,2)\n",
        "    #cal_fit = lambda l_x: mt.pow(l_x[0], 2) + mt.pow(l_x[1], 2) \n",
        "    #cal_fit = lambda l_x : l_x[0]**2 + l_x[1]**2 - 8*l_x[0] - 12*l_x[1] + 26\n",
        "    cal_fit = lambda l_x : l_x[0]**3 + 3*l_x[0]*l_x[1]**2 - 15*l_x[0] - 12*l_x[1]\n",
        "    #cal_fit = lambda l_x : l_x[0]**4 + l_x[1]**4 -2*( l_x[0] - l_x[1])**2\n",
        "\n",
        "    def __init__(self, num_ind = 4, num_in = 2):\n",
        "        import random as rd\n",
        "        import numpy as np\n",
        "        population = []\n",
        "        for _ in range(num_ind):\n",
        "            population.append([round(rd.uniform(0,20),5),round(rd.uniform(0,30),5)])\n",
        "        self.population = population\n",
        "\n",
        "    def rang_in(ind1, ind2):\n",
        "        if ind1[0] < 0:\n",
        "            ind1[0] = 0.0\n",
        "        elif ind1[0] > 20:\n",
        "            ind1[0] = 20.\n",
        "        if ind1[1] < 0:\n",
        "            ind1[1] = 0.0\n",
        "        elif ind1[1] > 30:\n",
        "            ind1[1] = 30.\n",
        "\n",
        "    def evaluate(self):\n",
        "        import numpy as np\n",
        "        import math as mt\n",
        "        inv = lambda x: 1/x\n",
        "        \n",
        "        l_ve = []\n",
        "        l_fitness = list(map(Agsimple.cal_fit , self.population))\n",
        "        min_f = Agsimple.min_value(l_fitness)\n",
        "        if min_f < 0:\n",
        "            l_fitness = Agsimple.is_negative(l_fitness, min_f)\n",
        "        l_fit_inv = list(map(inv, l_fitness))\n",
        "        f_prom_inv = sum(l_fit_inv)/len(l_fitness)\n",
        "        for e in l_fit_inv:\n",
        "            l_ve.append(e/f_prom_inv)\n",
        "        return l_fitness , l_ve\n",
        "\n",
        "    def selection_parents(self):\n",
        "        import random as rd\n",
        "        fitness, ve = Agsimple.evaluate(self)\n",
        "        T = sum(ve)\n",
        "        parents = []\n",
        "        n = len(self.population)\n",
        "        while len(parents) < int((n/2)):\n",
        "            sel, sel_tem = [] , []\n",
        "            for _ in range(2):\n",
        "                ve_sum = 0\n",
        "                r = rd.uniform(0, round(T))\n",
        "                for i in range(n):           \n",
        "                    ve_sum += ve[i]\n",
        "                    if ve_sum >= r:\n",
        "                        sel.append(i)\n",
        "                        break\n",
        "            sel_tem = sel.copy()\n",
        "            sel_tem.reverse()\n",
        "            if sel in parents or sel[0] == sel[1] or sel_tem in parents:\n",
        "                pass\n",
        "            else:\n",
        "                parents.append(sel)\n",
        "        return parents\n",
        "    \n",
        "    def __cal_beta(u,nc):\n",
        "        import math as mt\n",
        "        if u<=0.5:\n",
        "            beta = mt.pow(2*u, 1/(nc+1))\n",
        "        else: \n",
        "            beta = mt.pow(  1/(2*(1-u)) ,  1/(nc+1)  )\n",
        "        return beta\n",
        "\n",
        "    def cruza_SBX(self, nc=1):\n",
        "        import random as rd\n",
        "        import numpy as np\n",
        "        parents = self.selection_parents()\n",
        "        for i in range(len(parents)):\n",
        "            ind_p1, ind_p2 = parents[i][0], parents[i][1]\n",
        "            p1, p2 =np.array(self.population[ind_p1]),np.array(self.population[ind_p2])\n",
        "            u = rd.random()\n",
        "            beta = Agsimple.__cal_beta(u, nc)\n",
        "            h1 = 0.5*((p1+p2) - beta*(p2-p1))\n",
        "            h2 = 0.5*((p1+p2) + beta*(p2-p1))\n",
        "            #Agsimple.rang_in(h1,h2)\n",
        "            self.population.append(np.round(h1,5).tolist())\n",
        "            self.population.append(np.round(h2,5).tolist())\n",
        "        self.mutation_uniform()\n",
        "        \n",
        "    def new_poblation(self):\n",
        "        import random as rd\n",
        "        self.cruza_SBX(nc = 20)\n",
        "        fitness, ve = self.evaluate()\n",
        "        i = 0\n",
        "        for e in self.population:\n",
        "            e.insert(0, fitness[i])\n",
        "            i +=1\n",
        "        self.population.sort()\n",
        "        for i in range(len(self.population)):\n",
        "            if i <=(len(self.population)/2 -1):\n",
        "                self.population[i].pop(0)\n",
        "            else:\n",
        "                self.population.pop()\n",
        "        rd.shuffle(self.population)\n",
        "    \n",
        "    def mutation_uniform(self):\n",
        "        import random as rd\n",
        "        import numpy as np\n",
        "        x1_min, x1_max, x2_min, x2_max = 0, 20, 0 , 30\n",
        "        n = len(self.population)\n",
        "        pm = 1/len(self.population[0])\n",
        "        for i in range(int(n/2) , n ):\n",
        "            if rd.uniform(0,1) <= pm:\n",
        "                pos = rd.randint(0,1)\n",
        "                if pos == 0:\n",
        "                    self.population[i][pos] = round(rd.uniform(x1_min,x1_max),5)\n",
        "                else:\n",
        "                    self.population[i][pos] = round(rd.uniform(x2_min,x2_max),5)\n",
        "        '''\n",
        "        print('mutada')\n",
        "        for e in self.population:\n",
        "            print(e)\n",
        "        \n",
        "        fitness, ve = self.evaluate()\n",
        "        ind_fit = min(fitness)\n",
        "        ind_fit_index = fitness.index(ind_fit)\n",
        "        ind_best = self.population[ind_fit_index].copy()\n",
        "        ind_best = np.array(ind_best)\n",
        "        for i in range(int(n/2) , n ):\n",
        "            if uniform(0,1) <= pm:\n",
        "                ind_i = self.population[i].copy()\n",
        "                ind_i= np.array(ind_i)\n",
        "                delta = uniform(0,1)*(ind_best - ind_i)\n",
        "                ind_i_m = ind_i + delta\n",
        "                ind_i_m = ind_i_m.tolist()\n",
        "                self.population[i] = ind_i_m\n",
        "        print('mutada')\n",
        "        for e in self.population:\n",
        "            print(e)\n",
        "        '''\n",
        "    def graph_convergence(n_t, best_value):\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.plot(n_t, best_value)\n",
        "        plt.title('Gen vs Convergence')\n",
        "        plt.xlabel('Generacion')\n",
        "        plt.ylabel('best_value')\n",
        "        plt.grid()\n",
        "        plt.show()\n",
        "\n",
        "    def min_value(l):\n",
        "        return min(l)\n",
        "    \n",
        "    def is_negative(fitness, min_fit):\n",
        "        min_fit = abs(min_fit)\n",
        "        fitness = [min_fit + e +0.1 for e in fitness]\n",
        "        return fitness\n",
        "\n",
        "    \n",
        "    def algorithm_genetive(self, gen =10):\n",
        "        best_value_list = []\n",
        "        fitness, ve = self.evaluate()\n",
        "        best_value_list.append(Agsimple.min_value(fitness))\n",
        "        while Agsimple.t <= gen:\n",
        "            self.new_poblation()\n",
        "            fitness, ve = self.evaluate()\n",
        "            best_value_list.append(Agsimple.min_value(fitness))\n",
        "            Agsimple.t +=1\n",
        "        Agsimple.graph_convergence(range(Agsimple.t + 1), best_value_list )\n",
        "        #min = Agsimple.min_value(fitness)\n",
        "        x1,x2 =  self.population[0][0],self.population[0][1]\n",
        "        min = Agsimple.cal_fit([x1,x2])\n",
        "\n",
        "        print(\"Mínimo de la función: {}\\nEn las coordenadas: ({},{})\".format(min,x1,x2 ))\n",
        "        return min , [x1,x2]\n",
        "\n",
        "\n",
        "poblacion = Agsimple(num_ind= 50)\n",
        "poblacion.algorithm_genetive(gen=2000)"
      ],
      "metadata": {
        "id": "GxsBgJHW8HqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "a5c410ca-bd96-4ba9-abbf-f3a32273f0f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mínimo de la función: -27.999998773383886\n",
            "En las coordenadas: (2.00052,0.99978)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-27.999998773383886, [2.00052, 0.99978])"
            ],
            "image/png": "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\n",
            "text/latex": "$\\displaystyle \\left( -27.9999987733839, \\  \\left[ 2.00052, \\  0.99978\\right]\\right)$"
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import sympy as sp\n",
        "from sympy import *\n",
        "from sympy.abc import x\n",
        "import numpy as np\n",
        "import random as rd\n",
        "\n",
        "sp.init_printing()\n",
        "x1,x2 = sp.symbols('x1 x2')\n",
        "def gradient(f):\n",
        "    return [f.diff(x1), f.diff(x2)]\n",
        "\n",
        "def gradient2(f1):\n",
        "    return [[(f1[0].diff(x1)), (f1[0].diff(x2))],[(f1[1].diff(x1)),(f1[1].diff(x2))]]\n",
        "\n",
        "#f = x1**2+x2**2\n",
        "#f = x1**2 + x2**2 - 8*x1 -12*x2 + 26\n",
        "#f = (1.5 -x1*(1-x2))**2 + (2.25 -x1*(1-x2**2))**2 + (2.625 -x1*(1-x2**3))**2\n",
        "f = x1**3 + 3*x1*x2**2-15*x1 -12*x2\n",
        "#f = x1**4 + x2**4 - 2*(x1-x2)**2\n",
        "f_eva = lambdify((x1,x2) , f)\n",
        "print('Funcion : {}'.format(f))\n",
        "g = gradient(f)\n",
        "\n",
        "\n",
        "gx = lambdify((x1,x2) , g[0])\n",
        "gy = lambdify((x1,x2) , g[1])\n",
        "g2 = gradient2(g)\n",
        "g2xx = lambdify((x1,x2) , g2[0][0])\n",
        "g2yy = lambdify((x1,x2) , g2[1][1])\n",
        "g2xy = lambdify((x1,x2) , g2[0][1])\n",
        "g2yx = lambdify((x1,x2) , g2[1][0])\n",
        "\n",
        "epsilon = 0.000001\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEBO_2yYe8Kl",
        "outputId": "afc90919-8680-44e7-f49f-ff54656763ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Funcion : x1**3 + 3*x1*x2**2 - 15*x1 - 12*x2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "error = 11\n",
        "xk = np.array([round(rd.uniform(-20,10),5),round(rd.uniform(-30,10),5)]).reshape(2,1)\n",
        "while not(error < epsilon):\n",
        "    g2 = np.array([float(g2xx(xk[0],xk[1])) , float(g2xy(xk[0],xk[1])) , float(g2yx(xk[0],xk[1])) , float(g2yy(xk[0],xk[1]))]).reshape(2,2)\n",
        "    g2_inv = np.array(np.linalg.inv(g2))\n",
        "    print('G2 invers:')\n",
        "    print(g2_inv)\n",
        "    g_eva1 = float(gx(xk[0],xk[1]))\n",
        "    g_eva2 = float(gy(xk[0],xk[1]))\n",
        "    g_eval = np.matrix([g_eva1 ,g_eva2]).T\n",
        "\n",
        "    print('Gra evaluado')\n",
        "    print(g_eval)\n",
        "    xk_pre = xk.copy()\n",
        "    ajuste = g2_inv*g_eval\n",
        "    print('Ajuste')\n",
        "    print(ajuste)\n",
        "    ajuste.reshape(2,1)\n",
        "    xk = xk_pre - ajuste\n",
        "    #error = float(f_eva(xk[0],xk[1])) - float(f_eva(xk_pre[0],xk_pre[1]))\n",
        "    error = np.linalg.norm(g_eval)\n",
        "    print('error : {}'.format(error))\n",
        "    k+=1\n",
        "    print('Vector xk')\n",
        "    print(xk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l_-Bc30hUxT",
        "outputId": "2f36adb8-bd8c-45ec-d95c-af4257578838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G2 invers:\n",
            "[[0.02168532 0.01007293]\n",
            " [0.01007293 0.02168532]]\n",
            "Gra evaluado\n",
            "[[ 335.30246435]\n",
            " [-279.67858211]]\n",
            "Ajuste\n",
            "[[ 4.45396002]\n",
            " [-2.6874428 ]]\n",
            "error : 436.63239903252486\n",
            "Vector xk\n",
            "[[ 5.34626998]\n",
            " [-1.8648072 ]]\n",
            "G2 invers:\n",
            "[[0.03549259 0.01238   ]\n",
            " [0.01238    0.03549259]]\n",
            "Gra evaluado\n",
            "[[ 81.18032588]\n",
            " [-71.81857662]]\n",
            "Ajuste\n",
            "[[ 1.99218604]\n",
            " [-1.54401478]]\n",
            "error : 108.38889822272567\n",
            "Vector xk\n",
            "[[ 3.35408394]\n",
            " [-0.32079242]]\n",
            "G2 invers:\n",
            "[[0.05014941 0.00479641]\n",
            " [0.00479641 0.05014941]]\n",
            "Gra evaluado\n",
            "[[ 19.05836061]\n",
            " [-18.45578819]]\n",
            "Ajuste\n",
            "[[ 0.86724401]\n",
            " [-0.83413518]]\n",
            "error : 26.529930776284417\n",
            "Vector xk\n",
            "[[2.48683994]\n",
            " [0.51334276]]\n",
            "G2 invers:\n",
            "[[ 0.07000231 -0.01445014]\n",
            " [-0.01445014  0.07000231]]\n",
            "Gra evaluado\n",
            "[[ 4.34368097]\n",
            " [-4.34039239]]\n",
            "Ajuste\n",
            "[[ 0.36678697]\n",
            " [-0.36660428]]\n",
            "error : 6.14056759776221\n",
            "Vector xk\n",
            "[[2.12005297]\n",
            " [0.87994704]]\n",
            "G2 invers:\n",
            "[[ 0.09497634 -0.03942078]\n",
            " [-0.03942078  0.09497634]]\n",
            "Gra evaluado\n",
            "[[ 0.80679413]\n",
            " [-0.80679403]]\n",
            "Ajuste\n",
            "[[ 0.1084308]\n",
            " [-0.1084308]]\n",
            "error : 1.1409791349323728\n",
            "Vector xk\n",
            "[[2.01162216]\n",
            " [0.98837784]]\n",
            "G2 invers:\n",
            "[[ 0.10921809 -0.05366253]\n",
            " [-0.05366253  0.10921809]]\n",
            "Gra evaluado\n",
            "[[ 0.07054343]\n",
            " [-0.07054343]]\n",
            "Ajuste\n",
            "[[ 0.01149016]\n",
            " [-0.01149016]]\n",
            "error : 0.09976347932906189\n",
            "Vector xk\n",
            "[[2.00013201]\n",
            " [0.99986799]]\n",
            "G2 invers:\n",
            "[[ 0.11108912 -0.05553356]\n",
            " [-0.05553356  0.11108912]]\n",
            "Gra evaluado\n",
            "[[ 0.00079214]\n",
            " [-0.00079214]]\n",
            "Ajuste\n",
            "[[ 0.00013199]\n",
            " [-0.00013199]]\n",
            "error : 0.0011202584640552119\n",
            "Vector xk\n",
            "[[2.00000002]\n",
            " [0.99999998]]\n",
            "G2 invers:\n",
            "[[ 0.11111111 -0.05555555]\n",
            " [-0.05555555  0.11111111]]\n",
            "Gra evaluado\n",
            "[[ 1.04526382e-07]\n",
            " [-1.04526386e-07]]\n",
            "Ajuste\n",
            "[[ 1.74210633e-08]\n",
            " [-1.74210635e-08]]\n",
            "error : 1.478226298683229e-07\n",
            "Vector xk\n",
            "[[2.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(float(f_eva(xk[0],xk[1])))\n",
        "print(k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq4CkEAOjFXL",
        "outputId": "979c0eec-e52b-4fa3-8cfc-ef7007702a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-28.0\n",
            "8\n"
          ]
        }
      ]
    }
  ]
}